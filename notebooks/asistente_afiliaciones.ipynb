{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "085cb542",
   "metadata": {},
   "source": [
    "# Asistente de Afiliaciones ‚Äî Texto + Imagen\n",
    "\n",
    "Este proyecto implementa un **asistente conversacional** para agentes de Afiliaciones (IOMA) usando la **versi√≥n v6** de mi prompt optimizado.  \n",
    "El asistente responde **exclusivamente en JSON**, toma contexto de una **base de conocimiento** (CSV) y genera una **imagen institucional** seg√∫n el tema de la consulta (p. ej., ‚Äúafiliaci√≥n de reci√©n nacido/a‚Äù, ‚Äúestudiante‚Äù, ‚Äúconviviente‚Äù), con **cache** de im√°genes para ahorrar costos.\n",
    "\n",
    "**Qu√© incluye:**\n",
    "- *System prompt v6* (reglas fijas, JSON estricto).\n",
    "- B√∫squeda de **FAQ** por relevancia (tokens, t√≠tulos, contenido, palabras clave).\n",
    "- **Chat con memoria** (historial) y funci√≥n `reset_history()`.\n",
    "- **Im√°genes** con paleta IOMA (genera a 1024√ó1024 y muestra miniatura 256√ó256; reutiliza desde `imgs/`).\n",
    "- **UI con ipywidgets**: banner de bienvenida, texto a la izquierda e imagen a la derecha.\n",
    "- **Snapshot para GitHub**: genera una vista est√°tica (banner + JSON + imagen) que se ve bien en GitHub.\n",
    "\n",
    "> **Modelos usados:** `gpt-4o-` (texto) y `dall-e-3` (im√°genes, con fallback a `gpt-image-1`).  \n",
    "> **Requisitos:** `OPENAI_API_KEY` en `.env` o variable de entorno y el CSV en `../data/base_conocimiento_afiliaciones_clean.csv` (ajustable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4b3a715e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, json\n",
    "import pandas as pd\n",
    "from textwrap import dedent\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import base64, requests, unicodedata\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "load_dotenv()  # toma OPENAI_API_KEY del .env si existe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8962ad30",
   "metadata": {},
   "source": [
    "## Carga base de conocimiento (CSV)\n",
    "\n",
    "Carga el CSV con normativa/FAQs, filtra por `estado ‚àà {\"vigente\",\"en revisi√≥n\"}` y normaliza columnas clave.  \n",
    "Ajust√° `CSV_PATH` si tu ruta es distinta. Si el archivo no existe, el notebook avisa con `FileNotFoundError`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b8525e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas cargadas: 18\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# üëá Ajust√° la ruta si hace falta\n",
    "CSV_PATH = \"../data/base_conocimiento_afiliaciones_clean.csv\"\n",
    "\n",
    "p = Path(CSV_PATH)\n",
    "if not p.exists():\n",
    "    raise FileNotFoundError(f\"CSV no encontrado: {p.resolve()} ‚Äî ajust√° CSV_PATH.\")\n",
    "\n",
    "df = pd.read_csv(p, dtype=str, keep_default_na=False)\n",
    "df = df[df[\"estado\"].str.lower().isin([\"vigente\",\"en revisi√≥n\"])].copy()\n",
    "\n",
    "for col in [\"id\",\"titulo\",\"contenido\",\"respuesta_validada\",\"palabras_clave\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(\"\").astype(str)\n",
    "\n",
    "print(\"Filas cargadas:\", len(df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91807a37",
   "metadata": {},
   "source": [
    "## Helpers de b√∫squeda (tokens, ranking, top-1)\n",
    "\n",
    "En este bloque implemento un buscador **ligero** para elegir la FAQ m√°s relevante a partir del texto de la consulta. Opt√© por una heur√≠stica simple en vez de embeddings para mantener el costo en cero y la latencia m√≠nima.\n",
    "\n",
    "**Qu√© hago paso a paso:**\n",
    "1. **Normalizaci√≥n y tokenizaci√≥n.** Paso el texto a min√∫sculas y separo por caracteres no alfanum√©ricos, contemplando acentos (`√°√©√≠√≥√∫√±√º`) para espa√±ol. Esto me evita depender de stopwords externas y funciona bien para t√≠tulos cortos.\n",
    "2. **Puntaje por campo (ponderado).** Calculo un score por coincidencias de tokens entre la consulta y cada fila de la tabla:\n",
    "   - `+3` por coincidencias con **palabras_clave** (curadas a mano).\n",
    "   - `+2` en el **t√≠tulo** (alta se√±al).\n",
    "   - `+1` en el **contenido** (cobertura m√°s laxa).\n",
    "3. **Selecci√≥n top-1.** Me quedo con la fila de mayor puntaje; si nadie supera 0, no selecciono FAQ y dejo la **BASE vac√≠a** (la v6 ya define qu√© hacer en ese caso).\n",
    "\n",
    "**Por qu√© esta heur√≠stica:**\n",
    "- Es **barata** (no llama a modelo para recuperar).\n",
    "- Es **predecible** y f√°cil de auditar (un puntaje por campo).\n",
    "- Me permite **priorizar** r√°pidamente entradas bien etiquetadas.\n",
    "\n",
    "**Limitaciones y mejoras posibles:**\n",
    "- No hace stemming ni sin√≥nimos; variantes como ‚Äúrecien nacido‚Äù vs. ‚Äúreci√©n nacido‚Äù las manejo luego con reglas en im√°genes o ampliando palabras clave.\n",
    "- Se podr√≠a migrar a un **BM25** o a **embeddings** para mejorar recall; por ahora priorizo costo y simplicidad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ab0fc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dividir_en_tokens(texto: str):\n",
    "    texto = (texto or \"\").lower()\n",
    "    return [t for t in re.split(r\"[^a-z√°√©√≠√≥√∫√±√º0-9]+\", texto) if t]\n",
    "\n",
    "def calcular_relevancia(tokens_consulta, fila):\n",
    "    puntaje = 0\n",
    "    puntaje += 3 * len(set(tokens_consulta) & set(dividir_en_tokens(fila.get(\"palabras_clave\",\"\"))))\n",
    "    puntaje += 2 * len(set(tokens_consulta) & set(dividir_en_tokens(fila.get(\"titulo\",\"\"))))\n",
    "    puntaje += 1 * len(set(tokens_consulta) & set(dividir_en_tokens(fila.get(\"contenido\",\"\"))))\n",
    "    return puntaje\n",
    "\n",
    "def buscar_faq(consulta: str, tabla: pd.DataFrame):\n",
    "    toks = dividir_en_tokens(consulta)\n",
    "    puntuadas = [(calcular_relevancia(toks, fila), idx) for idx, fila in tabla.iterrows()]\n",
    "    puntuadas = [(p,i) for p,i in puntuadas if p>0]\n",
    "    if not puntuadas:\n",
    "        return None\n",
    "    puntuadas.sort(reverse=True)\n",
    "    return tabla.loc[puntuadas[0][1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7420ffb6",
   "metadata": {},
   "source": [
    "## System Prompt fijo + contexto por turno\n",
    "\n",
    "- **`SYSTEM_PROMPT_V6`**: reglas permanentes (JSON estricto, fuentes y limitaciones).\n",
    "- **`build_context_v6`**: para *cada pregunta*, construye el bloque con `Pregunta` y `<<BASE>> ... <<FIN_BASE>>` (compactada).  \n",
    "Si no hay BASE, la respuesta debe indicar ‚ÄúNo consta en la normativa adjunta‚Äù cuando corresponda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb6cce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compactar_texto(s: str, max_chars=800):\n",
    "    s = re.sub(r\"\\s+\", \" \", (s or \"\")).strip()\n",
    "    return s[:max_chars]\n",
    "\n",
    "# a) System prompt fijo (v6)\n",
    "SYSTEM_PROMPT_V6 = dedent(\"\"\"\n",
    "Rol: Asistente de Afiliaciones de IOMA. P√∫blico: agentes. Tono: institucional.\n",
    "\n",
    "Instrucciones:\n",
    "- \"checklist\": SOLO de <<BASE>>. Si falta dato: \"No consta en la normativa adjunta\".\n",
    "- \"terminos_clave\" y \"objetivo_y_buenas_practicas\": pod√©s usar conocimiento externo.\n",
    "- Responder SOLO con JSON v√°lido.\n",
    "\n",
    "Formato:\n",
    "{\n",
    "  \"checklist\": [\"...\", \"...\"],\n",
    "  \"terminos_clave\": [\"T√©rmino: definici√≥n breve\", \"...\", \"...\"],\n",
    "  \"objetivo_y_buenas_practicas\": [\"Buena pr√°ctica: detalle breve\", \"...\", \"...\"],\n",
    "  \"cierre\": \"Fuente: base de conocimiento vigente\"\n",
    "}\n",
    "\"\"\").strip()\n",
    "\n",
    "# b) Contexto din√°mico por turno (Pregunta + BASE)\n",
    "def build_context_v6(fila, pregunta: str):\n",
    "    if fila is None:\n",
    "        base = \"\"\n",
    "        idtitulo = \"(ninguna)\"\n",
    "    else:\n",
    "        base = (fila.get(\"respuesta_validada\") or \n",
    "                fila.get(\"contenido\") or \n",
    "                fila.get(\"titulo\",\"\")).strip()\n",
    "        base = compactar_texto(base, 800)\n",
    "        idtitulo = f\"{fila.get('id','(sin id)')} ‚Äì {fila.get('titulo','(sin t√≠tulo)')}\"\n",
    "    payload = dedent(f'''\n",
    "    Pregunta: \"{pregunta}\"\n",
    "\n",
    "    <<BASE>>\n",
    "    {base}\n",
    "    <<FIN_BASE>>\n",
    "    ''').strip()\n",
    "    return payload, idtitulo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1f7b3b",
   "metadata": {},
   "source": [
    "## Cliente OpenAI + modelo\n",
    "\n",
    "Inicializa el cliente con `OPENAI_API_KEY`.  \n",
    "Modelo de texto por defecto: **`gpt-4o`** (Se puede cambiar a `gpt-4o-mini` si esta disponible).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bdcf0ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente listo, modelo: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert api_key, \"Falta OPENAI_API_KEY (definila en .env o variable de entorno).\"\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "MODEL = \"gpt-4o\"  \n",
    "print(\"Cliente listo, modelo:\", MODEL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc0138",
   "metadata": {},
   "source": [
    "## Im√°genes: paleta IOMA, carpeta y utilidades\n",
    "\n",
    "Ac√° defino el **branding visual** y la **infra m√≠nima** para manejar im√°genes:\n",
    "\n",
    "- **Paleta IOMA.** Centralizo los colores institucionales (teal, p√∫rpura, magenta, blanco y gris). Los reutilizo en prompts y en la UI para un look consistente.\n",
    "- **Carpeta `imgs/`.** Creo (si no existe) un directorio local donde cacheo las im√°genes generadas por tema. Esto me permite reutilizarlas sin volver a gastar cr√©ditos.\n",
    "- **Utilidades.**\n",
    "  - `slugify()`: convierte el tema a un nombre de archivo seguro (ASCII, guiones).\n",
    "  - `resize_to()`: genero una **miniatura 256√ó256** para la UI, partiendo del PNG 1024√ó1024 original.\n",
    "  \n",
    "**Decisiones de dise√±o:**\n",
    "- **1024√ó1024** para generaci√≥n: la imagen sale m√°s n√≠tida y luego hago *downscale* a 256√ó256 para mostrar r√°pido en el chat.\n",
    "- El **cache** reduce costos y acelera la respuesta en repreguntas sobre el mismo tema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ab0a863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paleta IOMA\n",
    "PALETA_IOMA = {\n",
    "    \"teal\":    \"#2D8DA6\",\n",
    "    \"purpura\": \"#6A5AAE\",\n",
    "    \"magenta\": \"#C4286F\",\n",
    "    \"blanco\":  \"#FFFFFF\",\n",
    "    \"gris\":    \"#3C3C3C\",\n",
    "}\n",
    "\n",
    "IMGS_DIR = Path(\"imgs\")\n",
    "IMGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    s = unicodedata.normalize(\"NFKD\", s).encode(\"ascii\", \"ignore\").decode(\"ascii\")\n",
    "    s = re.sub(r\"[^a-zA-Z0-9]+\", \"-\", s).strip(\"-\").lower()\n",
    "    return s or \"imagen\"\n",
    "\n",
    "def resize_to(path_in: Path, path_out: Path, size=(256, 256)):\n",
    "    im = Image.open(path_in).convert(\"RGB\")\n",
    "    im = im.resize(size, Image.LANCZOS)\n",
    "    im.save(path_out, format=\"PNG\")\n",
    "    return path_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410fcc0",
   "metadata": {},
   "source": [
    "## Im√°genes: prompt visual y generaci√≥n con cache (1024‚Üí256)\n",
    "\n",
    "En este bloque armo el **prompt visual** y la mec√°nica de **generaci√≥n con cache**:\n",
    "\n",
    "- **Prompt visual.** Describo una ilustraci√≥n institucional, minimalista y c√°lida, con **degradado** en la paleta IOMA y un **halo** que refuerza el foco del tema. No incluyo textos en la imagen para evitar ruido y problemas de legibilidad.\n",
    "- **Modelos.** Uso `dall-e-3` y si falla hago **fallback** a `gpt-image-1`. Esto me da robustez sin frenar el flujo.\n",
    "- **Estrategia de cache.**\n",
    "  1. Si ya existe la miniatura `tema_256x256.png`, la uso tal cual.\n",
    "  2. Si solo existe el original `tema_1024.png`, genero la mini 256√ó256 en el momento.\n",
    "  3. Si no existe nada, **genero 1024**, guardo, y luego creo la **256**.\n",
    "\n",
    "**Beneficios:**\n",
    "- **Costo controlado:** ante temas repetidos no vuelvo a pedir im√°genes.\n",
    "- **Rendimiento:** el *downscale* local es instant√°neo.\n",
    "- **Consistencia visual:** el prompt forzado con colores y estilo mantiene una est√©tica homog√©nea en todo el asistente.\n",
    "\n",
    "**Notas operativas:**\n",
    "- El nombre de archivo deriva del **tema** (ej.: `afiliacion-de-recien-nacido-a_1024.png`).\n",
    "- Si un d√≠a cambio la paleta o el estilo, basta actualizar el prompt base para que las nuevas im√°genes sigan el branding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e27d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_MODEL_PRIMARY   = \"dall-e-3\"\n",
    "IMAGES_MODEL_FALLBACK  = \"gpt-image-1\"\n",
    "\n",
    "def build_prompt_imagen(tema: str) -> str:\n",
    "    return f\"\"\"\n",
    "Ilustraci√≥n institucional clara y elegante sobre **{tema}** como figura o escena central.\n",
    "Fondo con degradado arm√≥nico de la paleta IOMA \n",
    "(teal {PALETA_IOMA['teal']}, p√∫rpura {PALETA_IOMA['purpura']}, magenta {PALETA_IOMA['magenta']}).\n",
    "\n",
    "En lugar de c√≠rculos, destacar el sujeto principal con **un recuadro, panel o marco rectangular sutil**,\n",
    "o con bloques geom√©tricos detr√°s que sugieran orden y estructura.\n",
    "\n",
    "Evitar por completo s√≠mbolos o est√©tica religiosa.\n",
    "Estilo minimalista, moderno y c√°lido, sin texto en la imagen. Composici√≥n limpia y corporativa.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _generate_image_bytes(model: str, prompt_text: str, size: str = \"1024x1024\"):\n",
    "    resp = client.images.generate(model=model, prompt=prompt_text, n=1, size=size)\n",
    "    # Intentar URL\n",
    "    try:\n",
    "        url = resp.data[0].url\n",
    "        if url:\n",
    "            return requests.get(url, timeout=120).content\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Intentar b64_json\n",
    "    try:\n",
    "        b64 = resp.data[0].b64_json\n",
    "        if b64:\n",
    "            return base64.b64decode(b64)\n",
    "    except Exception:\n",
    "        pass\n",
    "    raise RuntimeError(\"No se pudo obtener la imagen (ni url ni b64_json).\")\n",
    "\n",
    "def get_or_create_image_for_theme(tema: str,\n",
    "                                  size_generate=\"1024x1024\",\n",
    "                                  size_display=(256, 256)) -> Path:\n",
    "    slug = slugify(tema)\n",
    "    p_full = IMGS_DIR / f\"{slug}_1024.png\"\n",
    "    p_disp = IMGS_DIR / f\"{slug}_{size_display[0]}x{size_display[1]}.png\"\n",
    "\n",
    "    if p_disp.exists():\n",
    "        return p_disp\n",
    "    if p_full.exists():\n",
    "        return resize_to(p_full, p_disp, size=size_display)\n",
    "\n",
    "    prompt_text = build_prompt_imagen(tema)\n",
    "    try:\n",
    "        img_bytes = _generate_image_bytes(IMAGES_MODEL_PRIMARY, prompt_text, size_generate)\n",
    "    except Exception:\n",
    "        img_bytes = _generate_image_bytes(IMAGES_MODEL_FALLBACK, prompt_text, size_generate)\n",
    "\n",
    "    Image.open(BytesIO(img_bytes)).convert(\"RGB\").save(p_full)\n",
    "    resize_to(p_full, p_disp, size=size_display)\n",
    "    return p_disp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d536ce9b",
   "metadata": {},
   "source": [
    "## Im√°genes: inferencia de tema + override `tema: ‚Ä¶`\n",
    "\n",
    "Ac√° decido **qu√© tema** ilustro en cada respuesta:\n",
    "\n",
    "- **Reglas por regex.** Busco palabras clave en la **consulta** y el **t√≠tulo** de la FAQ:  \n",
    "  ejemplos: `reci(eÃÅ)n nacid*`, `estudiante`, `conviviente`, `coÃÅnyuge`, `monotribut*`, etc.  \n",
    "  Esto cubre los casos m√°s comunes sin costo adicional.\n",
    "- **Orden de precedencia.**\n",
    "  1. Si el usuario escribe `tema: algo`, **respeto ese override**.\n",
    "  2. Si hay FAQ seleccionada, uso su **t√≠tulo** para dar contexto.\n",
    "  3. Si nada matchea, caigo a un **fallback** gen√©rico: ‚Äúafiliaciones IOMA‚Äù.\n",
    "- **Cache por tema.** Una vez resuelto el tema, reutilizo/creo la imagen correspondiente (ver Bloque B).\n",
    "\n",
    "**Por qu√© as√≠:**\n",
    "- El ‚Äúoverride‚Äù me permite **control total** en demos o casos borde.\n",
    "- Las **regex** son suficientes para este dominio acotado; si el alcance crece, puedo pasar a un clasificador liviano o a un mapeo de sin√≥nimos m√°s rico.\n",
    "\n",
    "**Mejoras futuras:**\n",
    "- Lista de **sin√≥nimos** por categor√≠a (ej.: ‚Äúneonato‚Äù, ‚Äúnacimiento‚Äù, ‚Äúalta del beb√©‚Äù ‚Üí reci√©n nacido/a).\n",
    "- Priorizar el **estado** de la FAQ (si hubiera varias candidatas) para elegir el tema m√°s actualizado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "876c0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tema_imagen(consulta: str, fila_sel) -> str:\n",
    "    # override manual si el usuario escribe 'tema: ...'\n",
    "    m = re.search(r\"tema\\s*:\\s*([^\\n\\r]+)\", consulta, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        override = m.group(1).strip()\n",
    "        if override:\n",
    "            return override\n",
    "\n",
    "    cand = (fila_sel.get(\"titulo\",\"\") if isinstance(fila_sel, dict) else (fila_sel[\"titulo\"] if fila_sel is not None and \"titulo\" in fila_sel else \"\")) or \"\"\n",
    "    texto_ref = f\"{consulta} {cand}\".lower()\n",
    "\n",
    "    rules = [\n",
    "        (r\"reci[e√©]n\\s*nacid[oa]\", \"afiliaci√≥n de reci√©n nacido/a\"),\n",
    "        (r\"recien\\s*nac\", \"afiliaci√≥n de reci√©n nacido/a\"),\n",
    "        (r\"estudiante\", \"afiliaci√≥n de estudiante\"),\n",
    "        (r\"conviviente\", \"afiliaci√≥n de conviviente\"),\n",
    "        (r\"c[o√≥]nyuge|conyuge\", \"afiliaci√≥n de c√≥nyuge\"),\n",
    "        (r\"monotribut\", \"afiliaci√≥n de monotributista\"),\n",
    "        (r\"padre|madre|progenitor\", \"afiliaci√≥n por v√≠nculo familiar\"),\n",
    "    ]\n",
    "    for pat, tema in rules:\n",
    "        if re.search(pat, texto_ref):\n",
    "            return tema\n",
    "\n",
    "    return cand.strip() or \"afiliaciones IOMA\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cab8d8",
   "metadata": {},
   "source": [
    "## Chat con memoria\n",
    "\n",
    "- Mantiene `chat_history` (incluye `SYSTEM_PROMPT_V6`) y guarda metadatos en `last_meta` (FAQ y tema detectado).\n",
    "- `chat(consulta)`: busca FAQ, arma contexto v6, llama al modelo y retorna **JSON en texto**.\n",
    "- `reset_history()`: reinicia la conversaci√≥n sin perder el *system prompt*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b16a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historial con v6\n",
    "chat_history = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT_V6}]\n",
    "last_meta = {\"fila_sel\": None, \"faq_idtitulo\": None, \"tema\": None}\n",
    "\n",
    "def reset_history():\n",
    "    global chat_history, last_meta\n",
    "    chat_history = [{\"role\": \"system\", \"content\": SYSTEM_PROMPT_V6}]\n",
    "    last_meta = {\"fila_sel\": None, \"faq_idtitulo\": None, \"tema\": None}\n",
    "    return \"Historial reiniciado (v6 cargada).\"\n",
    "\n",
    "def chat(consulta: str, temperature: float = 0.2, max_tokens: int = 400):\n",
    "    global last_meta\n",
    "\n",
    "    fila_sel = buscar_faq(consulta, df)\n",
    "    contexto, idtitulo = build_context_v6(fila_sel, consulta)\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": contexto})\n",
    "    resp = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=chat_history,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    assistant_msg = resp.choices[0].message.content\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "\n",
    "    tema = infer_tema_imagen(consulta, fila_sel.to_dict() if fila_sel is not None else {})\n",
    "    last_meta = {\n",
    "        \"fila_sel\": (fila_sel.to_dict() if fila_sel is not None else None),\n",
    "        \"faq_idtitulo\": idtitulo,\n",
    "        \"tema\": tema\n",
    "    }\n",
    "    return assistant_msg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68ea05",
   "metadata": {},
   "source": [
    "## UI con ipywidgets (banner, colores IOMA, texto + imagen)\n",
    "\n",
    "En este bloque construyo la **interfaz de chat** directamente en la notebook con `ipywidgets`, cuidando el **branding IOMA** y la legibilidad del JSON. La UI queda as√≠:\n",
    "\n",
    "- **Banner de bienvenida** con degrad√© y colores institucionales (teal‚Äìp√∫rpura‚Äìmagenta).\n",
    "- **Cuadro de texto** para escribir la consulta y botones **Enviar** / **Reset historial**.\n",
    "- **Panel de salida** que muestra cada turno con:\n",
    "  - **Izquierda:** la respuesta del asistente en un bloque `<pre>` (JSON puro), con tipograf√≠a legible, borde teal y fondo blanco.\n",
    "  - **Derecha:** una **miniatura 256√ó256** generada/cargada seg√∫n el **tema** detectado (p. ej., ‚Äúafiliaci√≥n de reci√©n nacido/a‚Äù), centrada verticalmente.\n",
    "  \n",
    "**C√≥mo funciona internamente:**\n",
    "- Al hacer click en **Enviar**, la UI llama a `chat(mensaje)`.  \n",
    "  Esa funci√≥n:\n",
    "  1) busca la FAQ m√°s relevante,  \n",
    "  2) arma el contexto v6 (Pregunta + `<<BASE>>`),  \n",
    "  3) consulta el modelo,  \n",
    "  4) infiere el **tema** para la imagen y guarda metadatos en `last_meta`.\n",
    "- Con el **tema**, la UI pide la miniatura a `get_or_create_image_for_theme(...)`.  \n",
    "  Si ya existe en `imgs/`, la reutiliza (cache); si no, genera el **1024√ó1024**, lo guarda y crea la mini **256√ó256**.\n",
    "\n",
    "**Personalizaciones √∫tiles:**\n",
    "- Puedo forzar el tema escribiendo `tema: estudiante` (o cualquier otro) dentro de mi mensaje.  \n",
    "- Puedo ajustar el tama√±o de la mini (por ejemplo, 192√ó192) si quiero m√°s compacidad visual.\n",
    "- El bot√≥n **Reset historial** limpia el di√°logo pero deja cargado el *system prompt* v6.\n",
    "\n",
    "**Requisitos y consideraciones:**\n",
    "- Para ver los widgets en VS Code necesito las extensiones **Jupyter** + **Notebook Renderers** y el paquete `ipywidgets` instalado.\n",
    "- En **GitHub** los widgets **no se renderizan**; para eso genero un **snapshot est√°tico** en el bloque de abajo. Igualmente adjunto una imagen de muestra con como se ve la ejecucion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dc28f377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a46cc476d5402181b03e22f19e4605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n        <div style=\"\\n            padding:14px 16px;\\n            border-radius:12px;\\n         ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ed818aa475441e80a9466355839bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='', description='Usuario:', layout=Layout(height='80px', width='100%'), placeholder='Ej: reci√©n‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6540f5df125c47a39d3f581811f7b79b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Enviar', style=ButtonStyle(button_color='#2D8DA6')), Button(description='Re‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153d9bba29c7433f9f954de73a168494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='2px solid #2D8DA6', border_left='2px solid #2D8DA6', border_right='2px sol‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# UI con estilos IOMA + banner + respuesta coloreada + imagen centrada\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    from pathlib import Path\n",
    "    import html\n",
    "\n",
    "    banner = widgets.HTML(\n",
    "        value=f\"\"\"\n",
    "        <div style=\"\n",
    "            padding:14px 16px;\n",
    "            border-radius:12px;\n",
    "            background: linear-gradient(90deg, {PALETA_IOMA['teal']}22, {PALETA_IOMA['purpura']}22, {PALETA_IOMA['magenta']}22);\n",
    "            border:1px solid {PALETA_IOMA['teal']};\n",
    "            \">\n",
    "          <div style=\"font-weight:700; font-size:16px; color:{PALETA_IOMA['teal']};\">\n",
    "            Bienvenido/a al Asistente de Afiliaciones\n",
    "          </div>\n",
    "          <div style=\"font-size:12.5px; color:{PALETA_IOMA['gris']};\">\n",
    "            Consult√° requisitos, documentaci√≥n y buenas pr√°cticas. Las respuestas siguen la BASE vigente y se devuelven en JSON.\n",
    "          </div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    input_box = widgets.Textarea(\n",
    "        value='',\n",
    "        placeholder='Ej: reci√©n nacido / estudiante / conviviente (pod√©s usar \"tema: estudiante\" para forzar)',\n",
    "        description='Usuario:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='100%', height='80px')\n",
    "    )\n",
    "    send_btn = widgets.Button(description='Enviar')\n",
    "    reset_btn = widgets.Button(description='Reset historial')\n",
    "\n",
    "    out = widgets.Output(layout=widgets.Layout(\n",
    "        border=f'2px solid {PALETA_IOMA[\"teal\"]}',\n",
    "        padding='8px',\n",
    "        max_height='520px',\n",
    "        overflow='auto'\n",
    "    ))\n",
    "\n",
    "    try:\n",
    "        send_btn.style.button_color  = PALETA_IOMA[\"teal\"]\n",
    "        reset_btn.style.button_color = PALETA_IOMA[\"magenta\"]\n",
    "    except Exception:\n",
    "        send_btn.button_style  = 'info'\n",
    "        reset_btn.button_style = 'warning'\n",
    "\n",
    "    def on_send_clicked(_):\n",
    "        with out:\n",
    "            user_text = input_box.value.strip()\n",
    "            if not user_text:\n",
    "                print(\"Escrib√≠ un mensaje primero.\")\n",
    "                return\n",
    "\n",
    "            display(widgets.HTML(\n",
    "                f\"<div style='margin-top:10px; font-weight:600; color:{PALETA_IOMA['purpura']};'>Usuario: {html.escape(user_text)}</div>\"\n",
    "            ))\n",
    "\n",
    "            ans = chat(user_text)\n",
    "\n",
    "            faq_label = html.escape(last_meta.get('faq_idtitulo','(ninguna)') or '(ninguna)')\n",
    "            ans_html = html.escape(ans)\n",
    "            left_panel = widgets.HTML(\n",
    "                value=f\"\"\"\n",
    "                <div style=\"font-family: Segoe UI, Roboto, Arial, sans-serif; color:{PALETA_IOMA['gris']}; line-height:1.45;\">\n",
    "                  <div style=\"font-size:12px; opacity:.8;\">FAQ seleccionada: {faq_label}</div>\n",
    "                  <div style=\"font-weight:700; margin:6px 0 8px 0; color:{PALETA_IOMA['teal']};\">Asistente</div>\n",
    "                  <pre style=\"\n",
    "                      white-space:pre-wrap;\n",
    "                      background:#FFFFFF;\n",
    "                      color:{PALETA_IOMA['gris']};\n",
    "                      border:1px solid {PALETA_IOMA['teal']};\n",
    "                      border-radius:10px;\n",
    "                      padding:12px;\n",
    "                      box-shadow: 0 1px 4px rgba(0,0,0,.06);\n",
    "                      \">{ans_html}</pre>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                tema = last_meta.get(\"tema\") or \"afiliaciones IOMA\"\n",
    "                path_256 = get_or_create_image_for_theme(\n",
    "                    tema, size_generate=\"1024x1024\", size_display=(256, 256)\n",
    "                )\n",
    "                img_bytes = Path(path_256).read_bytes()\n",
    "                img_widget = widgets.Image(value=img_bytes, format='png', width=256, height=256)\n",
    "                caption = widgets.HTML(\n",
    "                    f\"<div style='text-align:center;color:{PALETA_IOMA['gris']};font-size:12px;'>Imagen: {html.escape(tema)}</div>\"\n",
    "                )\n",
    "                right_panel = widgets.VBox(\n",
    "                    [img_widget, caption],\n",
    "                    layout=widgets.Layout(\n",
    "                        align_items='center',\n",
    "                        width='30%',\n",
    "                        align_self='center'   # centra verticalmente\n",
    "                    )\n",
    "                )\n",
    "            except Exception as e:\n",
    "                right_panel = widgets.HTML(\n",
    "                    f\"<div style='color:{PALETA_IOMA['magenta']};'>No se pudo mostrar la imagen ({html.escape(str(e))}).</div>\"\n",
    "                )\n",
    "\n",
    "            display(\n",
    "                widgets.HBox(\n",
    "                    [\n",
    "                        widgets.VBox([left_panel],  layout=widgets.Layout(width='70%')),\n",
    "                        right_panel\n",
    "                    ],\n",
    "                    layout=widgets.Layout(width='100%', align_items='center')\n",
    "                )\n",
    "            )\n",
    "\n",
    "            input_box.value = ''\n",
    "\n",
    "    def on_reset_clicked(_):\n",
    "        with out:\n",
    "            print(reset_history())\n",
    "\n",
    "    send_btn.on_click(on_send_clicked)\n",
    "    reset_btn.on_click(on_reset_clicked)\n",
    "\n",
    "    display(banner, input_box, widgets.HBox([send_btn, reset_btn]), out)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"UI opcional no disponible:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6572665f",
   "metadata": {},
   "source": [
    "## Snapshot est√°tico para GitHub (banner + JSON + imagen)\n",
    "\n",
    "GitHub **no** ejecuta widgets, as√≠ que si subo la notebook tal cual, el visor va a mostrar objetos (`HTML(...)`, `Textarea(...)`) en lugar de la UI.  \n",
    "Para resolverlo, agrego una celda que crea un **snapshot est√°tico** con todo lo necesario:\n",
    "\n",
    "- **Banner** en HTML (versi√≥n no-widget, renderizable por GitHub).\n",
    "- **FAQ seleccionada** (texto).\n",
    "- **Respuesta del asistente** en un bloque ```json (solo lectura).\n",
    "- **Imagen 256√ó256** embebida (quedar√° dentro del `.ipynb`, visible en GitHub).\n",
    "\n",
    "**C√≥mo lo uso:**\n",
    "1. Primero **chateo** con la UI hasta obtener una respuesta e imagen que me guste.  \n",
    "2. Luego ejecuto `snapshot_github()` (o `snapshot_github(\"reci√©n nacido\")` si quiero forzar una nueva).  \n",
    "3. **Guardo** la notebook con los outputs (no limpiar salidas) y la subo al repo.\n",
    "\n",
    "**Tips importantes:**\n",
    "- El snapshot embebe la miniatura (base64), por lo que el `.ipynb` puede crecer un poco; si necesito varias capturas, conviene limitar la cantidad de snapshots por notebook.\n",
    "- Si al ejecutar el snapshot no hay respuesta previa, puedo pasar el mensaje directamente: `snapshot_github(\"conviviente\")`.\n",
    "\n",
    "Con este flujo, en GitHub se ve **exactamente**: el banner, la FAQ, el JSON y la imagen, sin depender de widgets.\n",
    "\n",
    "‚ÑπÔ∏è **Nota:**  \n",
    "Esta funcionalidad de `snapshot_github()` la implement√© √∫nicamente para efectos de la entrega, \n",
    "con el objetivo de que el resultado final (banner + JSON + imagen) se visualice correctamente en el \n",
    "repositorio y los profesores puedan evaluarlo sin depender de widgets interactivos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "70d5d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Markdown, Image as IPyImage\n",
    "from pathlib import Path\n",
    "import html, json, re as _re\n",
    "\n",
    "def snapshot_github(mensaje: str | None = None, incluir_banner: bool = True):\n",
    "    # 1) Obtener respuesta y meta\n",
    "    if mensaje:\n",
    "        ans = chat(mensaje)  # actualiza last_meta\n",
    "    else:\n",
    "        ans = \"\"\n",
    "        for item in reversed(chat_history):\n",
    "            if item[\"role\"] == \"assistant\":\n",
    "                ans = item[\"content\"]; break\n",
    "        if not ans:\n",
    "            raise RuntimeError(\"No hay respuesta previa. Pas√° un 'mensaje' a snapshot_github().\")\n",
    "\n",
    "    faq_label = html.escape(last_meta.get(\"faq_idtitulo\", \"(ninguna)\") or \"(ninguna)\")\n",
    "    tema = last_meta.get(\"tema\") or \"afiliaciones IOMA\"\n",
    "    path_256 = get_or_create_image_for_theme(tema, size_generate=\"1024x1024\", size_display=(256, 256))\n",
    "\n",
    "    # 2) Banner EST√ÅTICO (no widget) -> esto s√≠ lo renderiza GitHub\n",
    "    if incluir_banner:\n",
    "        display(HTML(f\"\"\"\n",
    "        <div style=\"\n",
    "            padding:14px 16px;\n",
    "            border-radius:12px;\n",
    "            background: linear-gradient(90deg, {PALETA_IOMA['teal']}22, {PALETA_IOMA['purpura']}22, {PALETA_IOMA['magenta']}22);\n",
    "            border:1px solid {PALETA_IOMA['teal']};\n",
    "            font-family: Segoe UI, Roboto, Arial, sans-serif;\n",
    "            \">\n",
    "          <div style=\"font-weight:700; font-size:16px; color:{PALETA_IOMA['teal']};\">\n",
    "            Bienvenido/a al Asistente de Afiliaciones\n",
    "          </div>\n",
    "          <div style=\"font-size:12.5px; color:{PALETA_IOMA['gris']};\">\n",
    "            Consult√° requisitos, documentaci√≥n y buenas pr√°cticas. Las respuestas siguen la BASE vigente y se devuelven en JSON.\n",
    "          </div>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "\n",
    "    # 3) FAQ + respuesta en bloque + imagen\n",
    "    display(Markdown(f\"**FAQ seleccionada:** {faq_label}\"))\n",
    "    display(Markdown(\"**Asistente**\"))\n",
    "    display(Markdown(f\"```json\\n{ans}\\n```\"))\n",
    "    display(IPyImage(filename=str(path_256)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "008024bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No hay respuesta previa. Pas√° un 'mensaje' a snapshot_github().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msnapshot_github\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36msnapshot_github\u001b[39m\u001b[34m(mensaje, incluir_banner)\u001b[39m\n\u001b[32m     13\u001b[39m             ans = item[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]; \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ans:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo hay respuesta previa. Pas√° un \u001b[39m\u001b[33m'\u001b[39m\u001b[33mmensaje\u001b[39m\u001b[33m'\u001b[39m\u001b[33m a snapshot_github().\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m faq_label = html.escape(last_meta.get(\u001b[33m\"\u001b[39m\u001b[33mfaq_idtitulo\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m(ninguna)\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m(ninguna)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m tema = last_meta.get(\u001b[33m\"\u001b[39m\u001b[33mtema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mafiliaciones IOMA\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRuntimeError\u001b[39m: No hay respuesta previa. Pas√° un 'mensaje' a snapshot_github()."
     ]
    }
   ],
   "source": [
    "snapshot_github() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
